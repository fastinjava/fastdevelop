# 1.1 上下文切换

即使是单核处理器也支持多线程执行代码，CPU通过给每个线程分配CPU时间片来实现这个机制。时间片是CPU分配给各个线程的时间，因为时间片非常短，所以CPU通过不停地切换线程执行，让我们感觉多个线程是同时执行的，时间片一般是几十毫秒（ms）。



CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。



这就像我们同时读两本书，当我们在读一本英文的技术书时，发现某个单词不认识，于是便打开中英文字典，但是在放下英文技术书之前，大脑必须先记住这本书读到了多少页的第多少行，等查完单词之后，能够继续读这本书。这样的切换是会影响读书效率的，同样上下文切换也会影响多线程的执行速度。





## 1.1.1 多线程一定快吗

答案是不一定；

为什么并发执行的速度会比串行慢呢？这是因为线程有创建和上下文切换的开销。

## 1.1.2 测试上下文切换次数和时长

使用vmstat可以测试上下文切换次数；

使用Lmbench可以测试上下文切换的时长；



## 1.1.3 如何减少上下文切换时长



减少上下文切换的方法：

- 无锁并发编程
- CAS算法
- 使用最少线程和协程

无锁并发编程；

多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的id按照HASH算法取模分段，不同的线程处理不同段的数据。

CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁。

使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态。



·协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。



## 1.1.4 减少上下文切换实战



# 1.2 死锁

锁是个好东西，但是使用不当，会发生死锁现象。



死锁产生的四个条件：

```
1. 互斥使用，即当资源被一个线程使用(占有)时，别的线程不能使用

2. 不可抢占，资源请求者不能强制从资源占有者手中夺取资源，资源只能由资源占用者

    主动释放

3. 请求和保持，即当资源的请求者在请求其他的资源的同时保持对原有资源的占有

4. 循环等待，即存在一个等待队列: P1占有P2的资源，P2占有P3的资源，P3占有P1的资源。

    这样就形成了一个等待环路。
```





```java
package com.fastdevelop.demo;

import java.util.concurrent.SynchronousQueue;

public class DeadLockDemo {

    private static String A = "A";
    private static String B = "B";

    public static void main(String[] args) {
        new DeadLockDemo().deadLock();
    }

    private void deadLock() {
        Thread t1 = new Thread(() -> {
            synchronized (A) {
                try {
                    Thread.currentThread().sleep(2000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                synchronized (B){
                    System.out.println("1");
                }
            }
        });
        Thread t2 = new Thread(()->{
            synchronized (B){

                try {
                    Thread.currentThread().sleep(2000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }

                synchronized (A){
                    System.out.println("2");
                }
            }
        });
        t1.start();
        t2.start();
    }

}
```

比如说，上面示例代码就会引起死锁反应；

1、创建两个线程，分别线程1拿到A资源后休眠2秒。

2、线程2拿到B资源后，休眠2秒。

3、线程1持有A资源的同时，想要获取B资源，但是B资源被线程2所持有；

4、线程2持有B资源的同时，想要获取A资源，但是A资源被线程1所持有；

5、两者互相不解除占有就会发生死锁现象。





# 1.3 资源限制的挑战

（1）什么是资源限制
资源限制是指在进行并发编程时，程序的执行速度受限于计算机硬件资源或软件资源。例如，服务器的带宽只有2Mb/s，某个资源的下载速度是1Mb/s每秒，系统启动10个线程下载资源，下载速度不会变成10Mb/s，所以在进行并发编程时，要考虑这些资源的限制。硬件资源限制有带宽的上传/下载速度、硬盘读写速度和CPU的处理速度。软件资源限制有数据库的连接数和socket连接数等。

（2）资源限制引发的问题
在并发编程中，将代码执行速度加快的原则是将代码中串行执行的部分变成并发执行，但是如果将某段串行的代码并发执行，因为受限于资源，仍然在串行执行，这时候程序不仅不会加快执行，反而会更慢，因为增加了上下文切换和资源调度的时间。例如，之前看到一段程序使用多线程在办公网并发地下载和处理数据时，导致CPU利用率达到100%，几个小时都不能运行完成任务，后来修改成单线程，一个小时就执行完成了。



（3）如何解决资源限制的问题
对于硬件资源限制，可以考虑使用集群并行执行程序。既然单机的资源有限制，那么就让程序在多机上运行。比如使用ODPS、Hadoop或者自己搭建服务器集群，不同的机器处理不同的数据。可以通过“数据ID%机器数”，计算得到一个机器编号，然后由对应编号的机器处理这笔数据。

对于软件资源限制，可以考虑使用资源池将资源复用。比如使用连接池将数据库和Socket 连接复用，或者在调用对方webservice接口获取数据时，只建立一个连接。



（4）在资源限制情况下进行并发编程

如何在资源限制的情况下，让程序执行得更快呢？方法就是，根据不同的资源限制调整程序的并发度，比如下载文件程序依赖于两个资源——带宽和硬盘读写速度。有数据库操作时，涉及数据库连接数，如果SQL语句执行非常快，而线程的数量比数据库连接数大很多，则某些线程会被阻塞，等待数据库连接。



